{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125ae885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "from torch import nn\n",
    "import re\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af23a3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#sentences:100000'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d2l.DATA_HUB['ptb']=(d2l.DATA_URL+'ptb.zip','319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "def read_ptb():\n",
    "    data_dir=r\"..\\..\\FILE Module\\cmx.smali\"  #d2l.download_extract('ptb')\n",
    "    with open(data_dir) as f:\n",
    "        raw_text=f.read()\n",
    "        dot=[':','.','=','#','/',';','{','}','-','>','<','[',']','(',')',',','\"']\n",
    "        for s in dot:\n",
    "            raw_text=raw_text.replace(s,' ')\n",
    "    f.close()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "sentences=read_ptb()[:100000]\n",
    "f'#sentences:{len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1855cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,tokens=None,min_freq=0,reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens=[]\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens=[]\n",
    "        counter=count_corpus(tokens)\n",
    "        self._token_freqs=sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "        self.idx_to_token=['<unk>']+reserved_tokens\n",
    "        self.token_to_idx={token:idx for idx,token in enumerate(self.idx_to_token)}\n",
    "        for token,freq in self._token_freqs:\n",
    "            if freq<min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token]=len(self.idx_to_token)-1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            return self.token_to_idx.get(tokens,self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        if not isinstance(indices,(list,tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "    \n",
    "    def unk(self):\n",
    "        return 0\n",
    "    \n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "def count_corpus(tokens):\n",
    "    if len(tokens)==0 or isinstance(tokens[0],list):\n",
    "        tokens=[token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49f285d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<unk>', 0), ('Landroid', 1), ('support', 2), ('constraint', 3), ('v0', 4), ('solver', 5), ('line', 6), ('object', 7), ('widgets', 8), ('I', 9)]\n"
     ]
    }
   ],
   "source": [
    "vocab=Vocab(sentences)\n",
    "print(list(vocab.token_to_idx.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900acc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本 ['class', 'public', 'Landroid', 'arch', 'core', 'internal', 'FastSafeIterableMap']\n",
      "索引 [124, 34, 1, 54, 98, 99, 329]\n",
      "文本 ['end', 'annotation']\n",
      "索引 [19, 21]\n"
     ]
    }
   ],
   "source": [
    "for i in [0,10]:\n",
    "    print('文本',sentences[i])\n",
    "    print('索引',vocab[sentences[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "268eca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Landroid', 22777),\n",
       " ('support', 17983),\n",
       " ('constraint', 13925),\n",
       " ('v0', 12198),\n",
       " ('solver', 11766),\n",
       " ('line', 10123),\n",
       " ('object', 9423),\n",
       " ('widgets', 8344),\n",
       " ('I', 7878),\n",
       " ('Ljava', 7016)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=[token for line in sentences for token in line]\n",
    "vocab=Vocab(corpus)\n",
    "vocab._token_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bac52f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124, 34, 1, 54, 98, 99, 329, 113, 1, 54]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[corpus[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b01a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus,batch_size,num_steps):\n",
    "    corpus=corpus[random.randint(0,num_steps-1):]\n",
    "    num_subseqs=(len(corpus)-1)//num_steps\n",
    "    initial_indices=list(range(0,num_steps*num_subseqs,num_steps))\n",
    "    random.shuffle(initial_indices)\n",
    "    \n",
    "    def data(pos):\n",
    "        return corpus[pos:pos+num_steps]\n",
    "    \n",
    "    num_batchs=num_subseqs//batch_size\n",
    "    for i in range(0,batch_size*num_batchs,batch_size):\n",
    "        initial_indices_per_batch=initial_indices[i:i+batch_size]\n",
    "        X=[data(j) for j in initial_indices_per_batch]\n",
    "        Y=[data(j+1) for j in initial_indices_per_batch]\n",
    "        yield torch.tensor(X),torch.tensor(Y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8cf40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[29, 30, 31, 32, 33],\n",
      "        [19, 20, 21, 22, 23]]) \n",
      "Y: tensor([[30, 31, 32, 33, 34],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "X: tensor([[ 4,  5,  6,  7,  8],\n",
      "        [14, 15, 16, 17, 18]]) \n",
      "Y: tensor([[ 5,  6,  7,  8,  9],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "X: tensor([[ 9, 10, 11, 12, 13],\n",
      "        [24, 25, 26, 27, 28]]) \n",
      "Y: tensor([[10, 11, 12, 13, 14],\n",
      "        [25, 26, 27, 28, 29]])\n"
     ]
    }
   ],
   "source": [
    "my_seq=list(range(35))\n",
    "for X,Y in seq_data_iter_random(my_seq,batch_size=2,num_steps=5):\n",
    "    print('X:',X,'\\nY:',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e42f88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus,batch_size,num_steps):\n",
    "    offset=random.randint(0,num_steps)\n",
    "    num_tokens=((len(corpus)-offset-1)//batch_size)*batch_size\n",
    "    Xs=torch.tensor(corpus[offset:offset+num_tokens])\n",
    "    Ys=torch.tensor(corpus[offset+1:offset+num_tokens+1])\n",
    "    Xs,Ys=Xs.reshape(batch_size,-1),Ys.reshape(batch_size,-1)\n",
    "    num_batchs=Xs.shape[1]//num_steps\n",
    "    for i in range(0,num_steps*num_batchs,num_steps):\n",
    "        X=Xs[:,i:i+num_steps]\n",
    "        Y=Ys[:,i:i+num_steps]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "816a10b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 0,  1,  2,  3,  4],\n",
      "        [17, 18, 19, 20, 21]]) \n",
      "Y: tensor([[ 1,  2,  3,  4,  5],\n",
      "        [18, 19, 20, 21, 22]])\n",
      "X: tensor([[ 5,  6,  7,  8,  9],\n",
      "        [22, 23, 24, 25, 26]]) \n",
      "Y: tensor([[ 6,  7,  8,  9, 10],\n",
      "        [23, 24, 25, 26, 27]])\n",
      "X: tensor([[10, 11, 12, 13, 14],\n",
      "        [27, 28, 29, 30, 31]]) \n",
      "Y: tensor([[11, 12, 13, 14, 15],\n",
      "        [28, 29, 30, 31, 32]])\n"
     ]
    }
   ],
   "source": [
    "for X,Y in seq_data_iter_sequential(my_seq,batch_size=2,num_steps=5):\n",
    "    print('X:',X,'\\nY:',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b16e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens,num_embed= 2048,4096\n",
    "rnn_layer = nn.GRU(num_embed, num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78102d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, embed_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        self.embed_size=embed_size\n",
    "        self.embed=nn.Embedding(self.vocab_size,self.embed_size)\n",
    "        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = self.embed(inputs).permute(1,0,2)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ba79cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ' '.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26294059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goto 658 2279 1357 1971 0x23 mWrapped actual right 2278 onSaveInstanceState'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "net = RNNModel(rnn_layer, vocab_size=len(vocab), embed_size=num_embed)\n",
    "net = net.to(device)\n",
    "predict_ch8(['goto'], 10, net, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "343fd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size,num_steps=32,35\n",
    "train_iter=seq_data_iter_sequential(vocab[corpus],batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39edce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch8(net,train_iter,vocab,lr,num_epochs,device,use_random_iter=False):\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    #animator=Animator(xlabel='epoch',ylabel='perplexity',legend=['train'],xlim=[10,num_epochs])\n",
    "    if isinstance(net,nn.Module):\n",
    "        updater=torch.optim.SGD(net.parameters(),lr)\n",
    "    else:\n",
    "        updater=lambda batch_size:sgd(net.params,lr,batch_size)\n",
    "    predict=lambda prefix:predict_ch8(prefix,50,net,vocab,device)\n",
    "    num_list,loss_list=[],[]\n",
    "    for epoch in range(num_epochs):\n",
    "        state,train_iter_new=None,list(train_iter)\n",
    "        #print(epoch)\n",
    "        for idx,(X,Y) in enumerate(train_iter_new):\n",
    "            #print(X,Y)\n",
    "            if state is None or use_random_iter:\n",
    "                state=net.begin_state(batch_size=X.shape[0],device=device)\n",
    "            else:\n",
    "                if isinstance(net,nn.Module) and not isinstance(state,tuple):\n",
    "                    state.detach_()\n",
    "                else:\n",
    "                    for s in state:\n",
    "                        s.detach_()\n",
    "            y=Y.T.reshape(-1)\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            y_hat,state=net(X,state)\n",
    "            l=loss(y_hat,y.long()).mean()\n",
    "            if isinstance(updater,torch.optim.Optimizer):\n",
    "                updater.zero_grad()\n",
    "                l.backward()\n",
    "                d2l.grad_clipping(net,1)\n",
    "                updater.step()\n",
    "            else:\n",
    "                l.backward()\n",
    "                d2l.grad_clipping(net,1)\n",
    "                updater(batch_size=1)\n",
    "            num_list.append(epoch+(idx+1)/len(train_iter))\n",
    "            loss_list.append(l.cpu().detach().numpy())\n",
    "            print(\"第{}轮的损失值为:{}\".format(int(num_list[-1])+1,loss_list[-1]))\n",
    "    return num_list,loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71391e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮的损失值为:0.28671568632125854\n",
      "第1轮的损失值为:0.069551482796669\n",
      "第1轮的损失值为:0.051891226321458817\n",
      "第1轮的损失值为:0.08044978231191635\n",
      "第1轮的损失值为:0.0520939901471138\n",
      "第1轮的损失值为:0.06302329897880554\n",
      "第1轮的损失值为:0.06441478431224823\n",
      "第1轮的损失值为:0.06777125597000122\n",
      "第1轮的损失值为:0.05605470761656761\n",
      "第1轮的损失值为:0.05883267894387245\n",
      "第1轮的损失值为:0.0544373020529747\n",
      "第1轮的损失值为:0.0672827810049057\n",
      "第1轮的损失值为:0.051205188035964966\n",
      "第1轮的损失值为:0.050125833600759506\n",
      "第1轮的损失值为:0.05991577357053757\n",
      "第1轮的损失值为:0.06042976304888725\n",
      "第1轮的损失值为:0.05012860149145126\n",
      "第1轮的损失值为:0.05693043768405914\n",
      "第1轮的损失值为:0.053749941289424896\n",
      "第1轮的损失值为:0.059924185276031494\n",
      "第1轮的损失值为:0.06370890140533447\n",
      "第1轮的损失值为:0.05704731494188309\n",
      "第1轮的损失值为:0.060312408953905106\n",
      "第1轮的损失值为:0.07642989605665207\n",
      "第1轮的损失值为:0.033369045704603195\n",
      "第1轮的损失值为:0.05201168358325958\n",
      "第1轮的损失值为:0.05346863716840744\n",
      "第1轮的损失值为:0.04433004558086395\n",
      "第1轮的损失值为:0.048684436827898026\n",
      "第1轮的损失值为:0.048947639763355255\n",
      "第1轮的损失值为:0.049385376274585724\n",
      "第1轮的损失值为:0.04834804683923721\n",
      "第1轮的损失值为:0.05470120534300804\n",
      "第1轮的损失值为:0.04855787009000778\n",
      "第1轮的损失值为:0.06349758058786392\n",
      "第1轮的损失值为:0.044904764741659164\n",
      "第1轮的损失值为:0.04351012036204338\n",
      "第1轮的损失值为:0.04975897818803787\n",
      "第1轮的损失值为:0.05144057050347328\n",
      "第1轮的损失值为:0.04964069649577141\n",
      "第1轮的损失值为:0.05911850184202194\n",
      "第1轮的损失值为:0.05807429179549217\n",
      "第1轮的损失值为:0.05698657035827637\n",
      "第1轮的损失值为:0.05551400035619736\n",
      "第1轮的损失值为:0.06395302712917328\n",
      "第1轮的损失值为:0.06733526289463043\n",
      "第1轮的损失值为:0.05964980274438858\n",
      "第1轮的损失值为:0.04381965100765228\n",
      "第1轮的损失值为:0.04733359441161156\n",
      "第1轮的损失值为:0.061007361859083176\n",
      "第1轮的损失值为:0.04738950729370117\n",
      "第1轮的损失值为:0.0664297491312027\n",
      "第1轮的损失值为:0.05820218473672867\n",
      "第1轮的损失值为:0.06520568579435349\n",
      "第1轮的损失值为:0.04481738805770874\n",
      "第1轮的损失值为:0.05549754202365875\n",
      "第1轮的损失值为:0.05508219450712204\n",
      "第1轮的损失值为:0.05371353402733803\n",
      "第1轮的损失值为:0.05740132927894592\n",
      "第1轮的损失值为:0.0705987960100174\n",
      "第1轮的损失值为:0.052772898226976395\n",
      "第1轮的损失值为:0.06582712382078171\n",
      "第1轮的损失值为:0.05803244560956955\n",
      "第1轮的损失值为:0.05388154834508896\n",
      "第1轮的损失值为:0.05880507826805115\n",
      "第1轮的损失值为:0.043251682072877884\n",
      "第1轮的损失值为:0.05397416651248932\n",
      "第1轮的损失值为:0.06297601759433746\n",
      "第1轮的损失值为:0.06098346784710884\n",
      "第1轮的损失值为:0.05845540016889572\n",
      "第1轮的损失值为:0.048352647572755814\n",
      "第1轮的损失值为:0.04979950189590454\n",
      "第1轮的损失值为:0.056001920253038406\n",
      "第1轮的损失值为:0.05795782059431076\n",
      "第1轮的损失值为:0.06014883145689964\n",
      "第1轮的损失值为:0.04716505855321884\n",
      "第1轮的损失值为:0.060661785304546356\n",
      "第1轮的损失值为:0.053295496851205826\n",
      "第1轮的损失值为:0.05857883021235466\n",
      "第1轮的损失值为:0.04682260751724243\n",
      "第1轮的损失值为:0.05711272731423378\n",
      "第1轮的损失值为:0.04475793614983559\n",
      "第1轮的损失值为:0.0606110654771328\n",
      "第1轮的损失值为:0.047190841287374496\n",
      "第1轮的损失值为:0.04824331775307655\n",
      "第1轮的损失值为:0.05006752535700798\n",
      "第1轮的损失值为:0.05013270303606987\n",
      "第1轮的损失值为:0.04660063982009888\n",
      "第1轮的损失值为:0.04642891883850098\n",
      "第1轮的损失值为:0.05413537099957466\n",
      "第1轮的损失值为:0.056057434529066086\n",
      "第1轮的损失值为:0.04948890209197998\n",
      "第1轮的损失值为:0.043458353728055954\n",
      "第1轮的损失值为:0.04519058018922806\n",
      "第1轮的损失值为:0.06247180700302124\n",
      "第1轮的损失值为:0.07127273082733154\n",
      "第1轮的损失值为:0.052480243146419525\n",
      "第1轮的损失值为:0.06524977087974548\n",
      "第1轮的损失值为:0.06774548441171646\n",
      "第1轮的损失值为:0.05815856158733368\n",
      "第1轮的损失值为:0.07002072036266327\n",
      "第1轮的损失值为:0.05255061015486717\n",
      "第1轮的损失值为:0.06338118016719818\n",
      "第1轮的损失值为:0.058269206434488297\n",
      "第1轮的损失值为:0.06528542190790176\n",
      "第1轮的损失值为:0.04739842563867569\n",
      "第1轮的损失值为:0.05547090992331505\n",
      "第1轮的损失值为:0.05255572497844696\n",
      "第1轮的损失值为:0.059992190450429916\n",
      "第1轮的损失值为:0.07733742147684097\n",
      "第1轮的损失值为:0.07094057649374008\n",
      "第1轮的损失值为:0.052741385996341705\n",
      "第1轮的损失值为:0.052209120243787766\n",
      "第1轮的损失值为:0.04892147332429886\n",
      "第1轮的损失值为:0.0467386431992054\n",
      "第1轮的损失值为:0.05744379013776779\n",
      "第1轮的损失值为:0.060025330632925034\n",
      "第1轮的损失值为:0.049089688807725906\n",
      "第1轮的损失值为:0.06107849255204201\n",
      "第1轮的损失值为:0.051461417227983475\n",
      "第1轮的损失值为:0.06491338461637497\n",
      "第1轮的损失值为:0.04888860508799553\n",
      "第1轮的损失值为:0.05719401314854622\n",
      "第1轮的损失值为:0.05006008222699165\n",
      "第1轮的损失值为:0.06749681383371353\n",
      "第1轮的损失值为:0.06335783004760742\n",
      "第1轮的损失值为:0.040864549577236176\n",
      "第1轮的损失值为:0.059137165546417236\n",
      "第1轮的损失值为:0.06103013455867767\n",
      "第1轮的损失值为:0.055750034749507904\n",
      "第1轮的损失值为:0.06038602441549301\n",
      "第1轮的损失值为:0.05518294498324394\n",
      "第1轮的损失值为:0.05964362993836403\n",
      "第1轮的损失值为:0.054904770106077194\n",
      "第1轮的损失值为:0.050676073879003525\n",
      "第1轮的损失值为:0.057032328099012375\n",
      "第1轮的损失值为:0.06169569864869118\n",
      "第1轮的损失值为:0.05108577013015747\n",
      "第1轮的损失值为:0.0594581663608551\n",
      "第1轮的损失值为:0.058173805475234985\n",
      "第1轮的损失值为:0.044383954256772995\n",
      "第1轮的损失值为:0.05459318310022354\n",
      "第1轮的损失值为:0.06128198653459549\n",
      "第1轮的损失值为:0.05282874032855034\n",
      "第1轮的损失值为:0.05641987547278404\n",
      "第1轮的损失值为:0.06933415681123734\n",
      "第1轮的损失值为:0.05729798600077629\n",
      "第1轮的损失值为:0.05709937587380409\n",
      "第1轮的损失值为:0.0561198927462101\n",
      "第1轮的损失值为:0.04828004166483879\n",
      "第1轮的损失值为:0.052085988223552704\n",
      "第1轮的损失值为:0.05952836573123932\n",
      "第1轮的损失值为:0.059184879064559937\n",
      "第1轮的损失值为:0.05562394857406616\n",
      "第1轮的损失值为:0.05681029334664345\n",
      "第1轮的损失值为:0.04866998270153999\n",
      "第1轮的损失值为:0.05758541077375412\n",
      "第1轮的损失值为:0.05178973451256752\n",
      "第1轮的损失值为:0.054443422704935074\n",
      "第1轮的损失值为:0.059653256088495255\n",
      "第1轮的损失值为:0.049731235951185226\n",
      "第1轮的损失值为:0.06329621374607086\n",
      "第1轮的损失值为:0.05346881225705147\n",
      "第1轮的损失值为:0.0599512904882431\n",
      "第1轮的损失值为:0.059295158833265305\n",
      "第1轮的损失值为:0.061022840440273285\n",
      "第1轮的损失值为:0.0590844489634037\n",
      "第1轮的损失值为:0.05569062381982803\n",
      "第1轮的损失值为:0.04937238246202469\n",
      "第1轮的损失值为:0.048321228474378586\n",
      "第1轮的损失值为:0.060957275331020355\n",
      "第1轮的损失值为:0.057393256574869156\n",
      "第1轮的损失值为:0.055757779628038406\n",
      "第1轮的损失值为:0.048573870211839676\n",
      "第1轮的损失值为:0.05056101828813553\n",
      "第1轮的损失值为:0.0490788072347641\n",
      "第1轮的损失值为:0.04999493807554245\n",
      "第1轮的损失值为:0.06022657826542854\n",
      "第1轮的损失值为:0.07745993882417679\n",
      "第1轮的损失值为:0.06345674395561218\n",
      "第1轮的损失值为:0.06750564277172089\n",
      "第1轮的损失值为:0.061120402067899704\n",
      "第1轮的损失值为:0.06522802263498306\n",
      "第1轮的损失值为:0.058763857930898666\n",
      "第1轮的损失值为:0.05300050973892212\n",
      "第1轮的损失值为:0.06371811777353287\n",
      "第1轮的损失值为:0.0596478134393692\n",
      "第1轮的损失值为:0.0648079514503479\n",
      "第1轮的损失值为:0.06648222357034683\n",
      "第1轮的损失值为:0.0704711303114891\n",
      "第1轮的损失值为:0.06320443004369736\n",
      "第1轮的损失值为:0.06222756206989288\n",
      "第1轮的损失值为:0.05405077710747719\n",
      "第1轮的损失值为:0.06994214653968811\n",
      "第1轮的损失值为:0.0646229088306427\n",
      "第1轮的损失值为:0.06268203258514404\n",
      "第1轮的损失值为:0.06813381612300873\n",
      "第1轮的损失值为:0.06988327950239182\n",
      "第1轮的损失值为:0.057051997631788254\n",
      "第1轮的损失值为:0.06994181871414185\n",
      "第1轮的损失值为:0.056998129934072495\n",
      "第1轮的损失值为:0.05739960819482803\n",
      "第1轮的损失值为:0.07330964505672455\n",
      "第1轮的损失值为:0.061808742582798004\n",
      "第1轮的损失值为:0.05423067510128021\n",
      "第1轮的损失值为:0.05791391059756279\n",
      "第1轮的损失值为:0.05542455613613129\n",
      "第1轮的损失值为:0.056244298815727234\n",
      "第1轮的损失值为:0.053207170218229294\n",
      "第1轮的损失值为:0.05391264706850052\n",
      "第1轮的损失值为:0.06080988422036171\n",
      "第1轮的损失值为:0.05108323693275452\n",
      "第1轮的损失值为:0.06246417760848999\n",
      "第1轮的损失值为:0.06224246695637703\n",
      "第1轮的损失值为:0.06715938448905945\n",
      "第1轮的损失值为:0.06191640719771385\n",
      "第1轮的损失值为:0.06436479836702347\n",
      "第1轮的损失值为:0.06167440488934517\n",
      "第1轮的损失值为:0.06621376425027847\n",
      "第1轮的损失值为:0.05378321558237076\n",
      "第1轮的损失值为:0.06705275923013687\n",
      "第1轮的损失值为:0.07170777767896652\n",
      "第1轮的损失值为:0.06518983840942383\n",
      "第1轮的损失值为:0.06823580712080002\n",
      "第1轮的损失值为:0.06147795915603638\n",
      "第1轮的损失值为:0.05939120054244995\n",
      "第1轮的损失值为:0.06604214757680893\n",
      "第1轮的损失值为:0.06769552826881409\n",
      "第1轮的损失值为:0.0515093058347702\n",
      "第1轮的损失值为:0.06974050402641296\n",
      "第1轮的损失值为:0.06306879967451096\n",
      "第1轮的损失值为:0.06136314570903778\n",
      "第1轮的损失值为:0.05600922182202339\n",
      "第1轮的损失值为:0.06410311162471771\n",
      "第1轮的损失值为:0.0622279979288578\n",
      "第1轮的损失值为:0.07019666582345963\n",
      "第1轮的损失值为:0.0705433040857315\n",
      "第1轮的损失值为:0.0667031928896904\n",
      "第1轮的损失值为:0.05661638453602791\n",
      "第1轮的损失值为:0.06346312910318375\n",
      "第1轮的损失值为:0.08298350870609283\n",
      "第1轮的损失值为:0.06266125291585922\n",
      "第1轮的损失值为:0.06236884370446205\n",
      "第1轮的损失值为:0.06957980245351791\n",
      "第1轮的损失值为:0.059714630246162415\n",
      "第1轮的损失值为:0.05948350206017494\n",
      "第1轮的损失值为:0.06618113070726395\n",
      "第1轮的损失值为:0.059027332812547684\n",
      "第1轮的损失值为:0.06317019462585449\n",
      "第1轮的损失值为:0.056178655475378036\n",
      "第1轮的损失值为:0.05123915150761604\n",
      "第1轮的损失值为:0.05730920657515526\n",
      "第1轮的损失值为:0.05752216652035713\n",
      "第1轮的损失值为:0.07647671550512314\n",
      "第1轮的损失值为:0.06286679208278656\n",
      "第1轮的损失值为:0.06584544479846954\n",
      "第1轮的损失值为:0.05338319018483162\n",
      "第1轮的损失值为:0.06122890114784241\n",
      "第1轮的损失值为:0.073575459420681\n",
      "第1轮的损失值为:0.050420768558979034\n",
      "第1轮的损失值为:0.06591305136680603\n",
      "第1轮的损失值为:0.05825645476579666\n",
      "第1轮的损失值为:0.06247963756322861\n",
      "第1轮的损失值为:0.07526952028274536\n",
      "第1轮的损失值为:0.07173672318458557\n",
      "第1轮的损失值为:0.061900269240140915\n",
      "第1轮的损失值为:0.0717494934797287\n",
      "第1轮的损失值为:0.05812377855181694\n",
      "第1轮的损失值为:0.06688797473907471\n",
      "第1轮的损失值为:0.05943719297647476\n",
      "第1轮的损失值为:0.07377339154481888\n",
      "第1轮的损失值为:0.07044456154108047\n",
      "第1轮的损失值为:0.07422909140586853\n",
      "第1轮的损失值为:0.07144516706466675\n",
      "第1轮的损失值为:0.07024030387401581\n",
      "第1轮的损失值为:0.06898898631334305\n",
      "第1轮的损失值为:0.0696764662861824\n",
      "第1轮的损失值为:0.0571039579808712\n",
      "第1轮的损失值为:0.07076351344585419\n",
      "第1轮的损失值为:0.05489840731024742\n",
      "第1轮的损失值为:0.07270374149084091\n",
      "第1轮的损失值为:0.06234929338097572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮的损失值为:0.0629388764500618\n",
      "第1轮的损失值为:0.05804916098713875\n",
      "第1轮的损失值为:0.08784431964159012\n",
      "第1轮的损失值为:0.06706945598125458\n",
      "第1轮的损失值为:0.05278360843658447\n",
      "第1轮的损失值为:0.0654369369149208\n",
      "第1轮的损失值为:0.07412279397249222\n",
      "第1轮的损失值为:0.07248439639806747\n",
      "第1轮的损失值为:0.05443271994590759\n",
      "第1轮的损失值为:0.06284268945455551\n",
      "第1轮的损失值为:0.048222772777080536\n",
      "第1轮的损失值为:0.05505229905247688\n",
      "第1轮的损失值为:0.05379301682114601\n",
      "第1轮的损失值为:0.058266859501600266\n",
      "第1轮的损失值为:0.06340648233890533\n",
      "第1轮的损失值为:0.04880229011178017\n",
      "第1轮的损失值为:0.05901753529906273\n",
      "第1轮的损失值为:0.05051674321293831\n",
      "第1轮的损失值为:0.056720126420259476\n",
      "第1轮的损失值为:0.05952288582921028\n",
      "第1轮的损失值为:0.04959414526820183\n",
      "第1轮的损失值为:0.05465858057141304\n",
      "第1轮的损失值为:0.05696948617696762\n",
      "第1轮的损失值为:0.061607688665390015\n",
      "第1轮的损失值为:0.0691981166601181\n",
      "第1轮的损失值为:0.0612199492752552\n",
      "第1轮的损失值为:0.08772344142198563\n",
      "第1轮的损失值为:0.05902489274740219\n",
      "第1轮的损失值为:0.06634020060300827\n",
      "第1轮的损失值为:0.0637434870004654\n",
      "第1轮的损失值为:0.06125553697347641\n",
      "第1轮的损失值为:0.07013488560914993\n",
      "第1轮的损失值为:0.061730772256851196\n",
      "第1轮的损失值为:0.06008223071694374\n",
      "第1轮的损失值为:0.061499159783124924\n",
      "第1轮的损失值为:0.06259260326623917\n",
      "第2轮的损失值为:0.06139287352561951\n",
      "第2轮的损失值为:0.24161823093891144\n",
      "第2轮的损失值为:0.05495002865791321\n",
      "第2轮的损失值为:0.04121760278940201\n",
      "第2轮的损失值为:0.06791509687900543\n",
      "第2轮的损失值为:0.0417095422744751\n",
      "第2轮的损失值为:0.05624724179506302\n",
      "第2轮的损失值为:0.04892473667860031\n",
      "第2轮的损失值为:0.06380646675825119\n",
      "第2轮的损失值为:0.05357205495238304\n",
      "第2轮的损失值为:0.05114125460386276\n",
      "第2轮的损失值为:0.05287956818938255\n",
      "第2轮的损失值为:0.06940347701311111\n",
      "第2轮的损失值为:0.0572160929441452\n",
      "第2轮的损失值为:0.051655035465955734\n",
      "第2轮的损失值为:0.058579519391059875\n",
      "第2轮的损失值为:0.05472857132554054\n",
      "第2轮的损失值为:0.05062887817621231\n",
      "第2轮的损失值为:0.05380392447113991\n",
      "第2轮的损失值为:0.04852956533432007\n",
      "第2轮的损失值为:0.06736113131046295\n",
      "第2轮的损失值为:0.058681782335042953\n",
      "第2轮的损失值为:0.06568624079227448\n",
      "第2轮的损失值为:0.056953124701976776\n",
      "第2轮的损失值为:0.0712994709610939\n",
      "第2轮的损失值为:0.03531457483768463\n",
      "第2轮的损失值为:0.05534600839018822\n",
      "第2轮的损失值为:0.05487489327788353\n",
      "第2轮的损失值为:0.04512519761919975\n",
      "第2轮的损失值为:0.050153687596321106\n",
      "第2轮的损失值为:0.0500371940433979\n",
      "第2轮的损失值为:0.05339791998267174\n",
      "第2轮的损失值为:0.05263037234544754\n",
      "第2轮的损失值为:0.06573302298784256\n",
      "第2轮的损失值为:0.05483560264110565\n",
      "第2轮的损失值为:0.06404699385166168\n",
      "第2轮的损失值为:0.04196353629231453\n",
      "第2轮的损失值为:0.04767357558012009\n",
      "第2轮的损失值为:0.05157976225018501\n",
      "第2轮的损失值为:0.056594088673591614\n",
      "第2轮的损失值为:0.055296413600444794\n",
      "第2轮的损失值为:0.05902589485049248\n",
      "第2轮的损失值为:0.061317648738622665\n",
      "第2轮的损失值为:0.05919976904988289\n",
      "第2轮的损失值为:0.060209982097148895\n",
      "第2轮的损失值为:0.06488780677318573\n",
      "第2轮的损失值为:0.06738466024398804\n",
      "第2轮的损失值为:0.05714868754148483\n",
      "第2轮的损失值为:0.045823950320482254\n",
      "第2轮的损失值为:0.04873836413025856\n",
      "第2轮的损失值为:0.06281791627407074\n",
      "第2轮的损失值为:0.04833848774433136\n",
      "第2轮的损失值为:0.061027295887470245\n",
      "第2轮的损失值为:0.056929927319288254\n",
      "第2轮的损失值为:0.06790488958358765\n",
      "第2轮的损失值为:0.048748865723609924\n",
      "第2轮的损失值为:0.05630769580602646\n",
      "第2轮的损失值为:0.050421133637428284\n",
      "第2轮的损失值为:0.05428234487771988\n",
      "第2轮的损失值为:0.05218137428164482\n",
      "第2轮的损失值为:0.0736517459154129\n",
      "第2轮的损失值为:0.05169288441538811\n",
      "第2轮的损失值为:0.06201639771461487\n",
      "第2轮的损失值为:0.0555175356566906\n",
      "第2轮的损失值为:0.05428604781627655\n",
      "第2轮的损失值为:0.060178764164447784\n",
      "第2轮的损失值为:0.04606430232524872\n",
      "第2轮的损失值为:0.0529823824763298\n",
      "第2轮的损失值为:0.06423820555210114\n",
      "第2轮的损失值为:0.05998871847987175\n",
      "第2轮的损失值为:0.061831530183553696\n",
      "第2轮的损失值为:0.05192641168832779\n",
      "第2轮的损失值为:0.05025964602828026\n",
      "第2轮的损失值为:0.05528806149959564\n",
      "第2轮的损失值为:0.05981321260333061\n",
      "第2轮的损失值为:0.05899861827492714\n",
      "第2轮的损失值为:0.05054036155343056\n",
      "第2轮的损失值为:0.05870165303349495\n",
      "第2轮的损失值为:0.05046515539288521\n",
      "第2轮的损失值为:0.06283558905124664\n",
      "第2轮的损失值为:0.04797763749957085\n",
      "第2轮的损失值为:0.06090459227561951\n",
      "第2轮的损失值为:0.048428382724523544\n",
      "第2轮的损失值为:0.06037906929850578\n",
      "第2轮的损失值为:0.04704751446843147\n",
      "第2轮的损失值为:0.04963676631450653\n",
      "第2轮的损失值为:0.05040108039975166\n",
      "第2轮的损失值为:0.0525820218026638\n",
      "第2轮的损失值为:0.04906518757343292\n",
      "第2轮的损失值为:0.04895089194178581\n",
      "第2轮的损失值为:0.05437483638525009\n",
      "第2轮的损失值为:0.0631178542971611\n",
      "第2轮的损失值为:0.0508350245654583\n",
      "第2轮的损失值为:0.045695945620536804\n",
      "第2轮的损失值为:0.04584860801696777\n",
      "第2轮的损失值为:0.05921456590294838\n",
      "第2轮的损失值为:0.0641327053308487\n",
      "第2轮的损失值为:0.045651305466890335\n",
      "第2轮的损失值为:0.060863569378852844\n",
      "第2轮的损失值为:0.061622899025678635\n",
      "第2轮的损失值为:0.05214307829737663\n",
      "第2轮的损失值为:0.06460662186145782\n",
      "第2轮的损失值为:0.04787697270512581\n",
      "第2轮的损失值为:0.05844340845942497\n",
      "第2轮的损失值为:0.05202510580420494\n",
      "第2轮的损失值为:0.05689133703708649\n",
      "第2轮的损失值为:0.043168142437934875\n",
      "第2轮的损失值为:0.05089456960558891\n",
      "第2轮的损失值为:0.044990576803684235\n",
      "第2轮的损失值为:0.05723147466778755\n",
      "第2轮的损失值为:0.07087988406419754\n",
      "第2轮的损失值为:0.058235909789800644\n",
      "第2轮的损失值为:0.043914780020713806\n",
      "第2轮的损失值为:0.04515663906931877\n",
      "第2轮的损失值为:0.046573705971241\n",
      "第2轮的损失值为:0.04609547182917595\n",
      "第2轮的损失值为:0.053921233862638474\n",
      "第2轮的损失值为:0.05261868238449097\n",
      "第2轮的损失值为:0.04514214023947716\n",
      "第2轮的损失值为:0.0576847605407238\n",
      "第2轮的损失值为:0.052920468151569366\n",
      "第2轮的损失值为:0.05923822894692421\n",
      "第2轮的损失值为:0.04241332411766052\n",
      "第2轮的损失值为:0.04419209435582161\n",
      "第2轮的损失值为:0.046548984944820404\n",
      "第2轮的损失值为:0.05646490305662155\n",
      "第2轮的损失值为:0.05647880584001541\n",
      "第2轮的损失值为:0.038322389125823975\n",
      "第2轮的损失值为:0.051022592931985855\n",
      "第2轮的损失值为:0.056818414479494095\n",
      "第2轮的损失值为:0.047036271542310715\n",
      "第2轮的损失值为:0.053399622440338135\n",
      "第2轮的损失值为:0.04769304022192955\n",
      "第2轮的损失值为:0.05616474896669388\n",
      "第2轮的损失值为:0.048694632947444916\n",
      "第2轮的损失值为:0.04388745129108429\n",
      "第2轮的损失值为:0.0431131049990654\n",
      "第2轮的损失值为:0.05736573785543442\n",
      "第2轮的损失值为:0.04354739189147949\n",
      "第2轮的损失值为:0.05421240255236626\n",
      "第2轮的损失值为:0.045498866587877274\n",
      "第2轮的损失值为:0.04263236001133919\n",
      "第2轮的损失值为:0.05220421403646469\n",
      "第2轮的损失值为:0.0557258203625679\n",
      "第2轮的损失值为:0.0492631159722805\n",
      "第2轮的损失值为:0.052093975245952606\n",
      "第2轮的损失值为:0.0621735155582428\n",
      "第2轮的损失值为:0.05335051938891411\n",
      "第2轮的损失值为:0.05385913327336311\n",
      "第2轮的损失值为:0.04880461469292641\n",
      "第2轮的损失值为:0.042864661663770676\n",
      "第2轮的损失值为:0.050740405917167664\n",
      "第2轮的损失值为:0.05800653249025345\n",
      "第2轮的损失值为:0.058370836079120636\n",
      "第2轮的损失值为:0.047467585653066635\n",
      "第2轮的损失值为:0.053463488817214966\n",
      "第2轮的损失值为:0.04296517372131348\n",
      "第2轮的损失值为:0.05237652733922005\n",
      "第2轮的损失值为:0.046162184327840805\n",
      "第2轮的损失值为:0.05098738148808479\n",
      "第2轮的损失值为:0.05664076656103134\n",
      "第2轮的损失值为:0.04464176669716835\n",
      "第2轮的损失值为:0.05445586517453194\n",
      "第2轮的损失值为:0.04937698319554329\n",
      "第2轮的损失值为:0.05587126687169075\n",
      "第2轮的损失值为:0.054577235132455826\n",
      "第2轮的损失值为:0.05499543622136116\n",
      "第2轮的损失值为:0.05484319105744362\n",
      "第2轮的损失值为:0.05107071250677109\n",
      "第2轮的损失值为:0.045460525900125504\n",
      "第2轮的损失值为:0.043917227536439896\n",
      "第2轮的损失值为:0.0546729639172554\n",
      "第2轮的损失值为:0.0551726333796978\n",
      "第2轮的损失值为:0.05309639498591423\n",
      "第2轮的损失值为:0.046852827072143555\n",
      "第2轮的损失值为:0.04855190962553024\n",
      "第2轮的损失值为:0.046469252556562424\n",
      "第2轮的损失值为:0.04639700427651405\n",
      "第2轮的损失值为:0.0501149483025074\n",
      "第2轮的损失值为:0.06825575232505798\n",
      "第2轮的损失值为:0.05822824686765671\n",
      "第2轮的损失值为:0.05735936760902405\n",
      "第2轮的损失值为:0.04735982045531273\n",
      "第2轮的损失值为:0.058725208044052124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m train_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(train_iter)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#type(train_iter)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m num_list,loss_list\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_ch8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[68], line 30\u001b[0m, in \u001b[0;36mtrain_ch8\u001b[1;34m(net, train_iter, vocab, lr, num_epochs, device, use_random_iter)\u001b[0m\n\u001b[0;32m     28\u001b[0m     updater\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 30\u001b[0m     \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_clipping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     updater\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Android malware analysis\\Machine Learning Module\\RNN\\../../..\\d2l\\torch.py:735\u001b[0m, in \u001b[0;36mgrad_clipping\u001b[1;34m(net, theta)\u001b[0m\n\u001b[0;32m    733\u001b[0m     params \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m    734\u001b[0m norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m(torch\u001b[38;5;241m.\u001b[39msum((p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params))\n\u001b[1;32m--> 735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnorm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m:\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    737\u001b[0m         param\u001b[38;5;241m.\u001b[39mgrad[:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m theta \u001b[38;5;241m/\u001b[39m norm\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs,lr=30,1\n",
    "train_iter=seq_data_iter_sequential(vocab[corpus],batch_size,num_steps)\n",
    "train_iter=list(train_iter)\n",
    "#type(train_iter)\n",
    "num_list,loss_list=train_ch8(net,train_iter,vocab,lr,num_epochs,d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4906dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goto 16 goto_0 line 2373 cond_17'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8(['goto'], 5, net, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f6c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch for deeplearing",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
